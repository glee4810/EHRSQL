<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records</title>
        <meta name="description" content="EHRSQL is a large-scale, high-quality text-to-SQL dataset for question answering (QA) on electronic health records (MIMIC-III and eICU). The questions were collected from 222 hospital staff, including physicians, nurses, insurance review and health records teams, etc. The dataset can be used to test three aspects of QA models over EHR tables: generating a wide range of SQL queries asked in the hospital workplace, understanding various time expressions (absolute, relative, or both), and the ability to abstain from answering when the model prediction is not confident. We call this task <q>trustworthy semantic parsing.</q>">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
		<link rel="shortcut icon" href="/EHRSQL/logo.png">
		<link rel="stylesheet" href="/EHRSQL/bower_components/bootstrap/dist/css/bootstrap.min.css">
		<link rel="stylesheet" href="/EHRSQL/stylesheets/layout.css">
		<link rel="stylesheet" href="/EHRSQL/stylesheets/index.css">
	</head>
	<body>
		<div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation">
			<div class="container clearfix" id="navContainer">
				<div class="leftNav">
					<div class="brandDiv"><a class="navbar-brand" href="/EHRSQL/">EHRSQL</a></div>
				</div>
				<div class="rightNav">
					<div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div>
					<div class="collapse navbar-collapse" id="navbar">
						<ul class="nav navbar-nav navbar-right">
							<li><a href="/EHRSQL/">Home</a></li>
						</ul>
					</div>
				</div>				
			</div>
		</div>
		<div class="cover" id="topCover">
			<div class="container">
				<div class="row">
					<div class="col-md-12">
						<h1 id="appTitle">EHRSQL</h1>
						<h2 id="appSubtitle">A Practical Text-to-SQL Benchmark for Electronic Health Records</h2>
					</div>
				</div>
			</div>
		</div>
		<div class="cover" id="contentCover">
			<div class="container">
				<div class="row">
					<div class="col-md-5">
						<div class="infoCard">
							<div class="infoBody">
								<div class="infoHeadline">
									<h2>What is EHRSQL?</h2>
								</div>
								<p>EHRSQL is a large-scale, high-quality text-to-SQL dataset for question answering (QA) on electronic health records (MIMIC-III and eICU). The questions were collected from 222 hospital staff, including physicians, nurses, insurance review and health records teams, etc. The dataset can be used to test three aspects of QA models over EHR tables: generating a wide range of SQL queries asked in the hospital workplace, understanding various time expressions (absolute, relative, or both), and the ability to abstain from answering when the model prediction is not confident. We call this task <q>trustworthy semantic parsing.</q></p>
                                <a class="btn actionBtn" href="https://arxiv.org/abs/2301.07695">EHRSQL Paper</a>
								<hr>
								<!-- <div class="infoHeadline">
									<h2>News</h2>
								</div>
								<ul class="list-unstyled" style="background-color:#f5f5f5">
									<li><span class="date label label-default" style="background-color:#4e8ac7"><i>09/26/2022</i></span>Evaluation script is updated (precision, recall, f1).</li>
									<li><span class="date label label-default" style="background-color:#4e8ac7"><i>09/16/2022</i></span>EHRSQL is accepted to NeurIPS 2022 Datasets and Benchmarks Track.</li>
								</ul> -->
								<div class="infoHeadline">
									<h2>Download</h2>
								</div>
                                <p> The dataset is distributed under the <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA 4.0</a> license.
								<ul class="list-unstyled">
									<li><a class="btn actionBtn inverseBtn" href="https://github.com/glee4810/EHRSQL/tree/main/dataset/ehrsql/mimic_iii" download>Training & Valid Set (MIMIC-III)</a></li>
									<li><a class="btn actionBtn inverseBtn" href="https://github.com/glee4810/EHRSQL/tree/main/dataset/ehrsql/eicu" download>Training & Valid Set (eICU)</a></li>
									<li><a class="btn actionBtn inverseBtn" href="https://github.com/glee4810/EHRSQL/blob/main/dataset/ehrsql/tables.json" download>DB Schema (MIMIC-III & eICU)</a></li>
								</ul>
								</p>
								<div class="infoHeadline">
									<h2>Evaluation</h2>
								</div>
								<p>To run the evaluation script, use <code>python evaluate.py --db_path &lt;path_to_db&gt; --data_file &lt;data_file&gt; --pred_file &lt;pred_file&gt;</code>. We highly recommend that the model prediction file should contain the generated SQL queries and null if abstained. EHRSQL tests not only how much a model can perform well in generating SQL queries but also the ability to abstain when the model is not sure of its prediction.
								<ul class="list-unstyled">
									<li><a class="btn actionBtn inverseBtn" href="https://github.com/glee4810/EHRSQL/blob/main/evaluate.py" download>Evaluation Script</a></li>
									<li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/bundles/0x35d84e0dc2874ecbb00648afeff76ed6/" download>Sample Prediction File</a></li>
								</ul>
								</p>
								<!-- <p>Once you are satisfied with your model performance on the dev set, you are encouraged to send your output to <a href="mailto:gyubok.lee@kaist.ac.kr">gyubok.lee@kaist.ac.kr</a> with your dev performance and the code to get the official scores on the test set.</p> -->
								<p>Once you have built a model that works to your expectations on the validation set, you can submit it to get official scores on a hidden test set. To preserve the integrity of test results, we do not release the test set to the public. Instead, we require you to submit your model and prediction script so that we can run it on the test set for you. Here's a tutorial walking you through official evaluation of your model:</p>
								<a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/worksheets/0x87677f3f7fe647d69f9e247c2be76b8e">Submission Tutorial</a>
								<a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/worksheets/0x9faffc67cff144deb175974509a9238f">Submission Tutorial (Codex)</a>
								<div class="infoHeadline">
									<h2>Trustworthy Semantic Parsing Example</h2>
								</div>
								<table class="table sample">
								  <tbody>
									<p><b>Answerable Question</b>: <br>
										Tell me the method of intake of clobetasol propionate 0.05% ointment?</p>
									<p><b>Systen output</b>: <br>
										select distinct prescriptions.route from prescriptions <br>
										where prescriptions.drug = 'clobetasol propionate 0.05% ointment' </p>
									<br>
									<p><b>Unanswerable Question</b>: <br>
										What is the name of the medication which should not be administered during the contrast arteriogram-leg treatment? (assume this is not answerable by the model)</p>
									<p><b>Systen output</b>: <br> 
										null
								</tbody>
								</table>
								<div class="infoHeadline">
									<h2>Have Questions?</h2>
								</div>
								<p> Ask us at our <a href="https://github.com/glee4810/EHRSQL/issues">Github issues page</a> or contact <a href="mailto:gyubok.lee@kaist.ac.kr">gyubok.lee@kaist.ac.kr</a>.</p>
                                <div class="infoHeadline">
                                    <h2>Acknowledgement</h2>
                                </div>
                                <p>The website is built based on <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD.  </a></p>
							</div>
							<div class="infoSubheadline">
								<!-- <a href="https://twitter.com/share" class="twitter-share-button" data-url="https://stanford-qa.com" data-text="The Stanford Question Answering Dataset - 100,000+ questions for reading comprehension" data-via="stanfordnlp" data-size="large" data-hashtags="SQuAD">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>Place this tag where you want the button to render. -->
								<a class="github-button" href="https://github.com/glee4810/EHRSQL" data-icon="octicon-star" data-style="mega" data-count-href="/glee4810/EHRSQL/stargazers" data-count-api="/repos/glee4810/EHRSQL#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star glee4810/EHRSQL on GitHub">Star</a>
							</div>
						</div>
					</div>
					<div class="col-md-7">
						<div class="infoCard">
							<div class="infoBody">
								<div class="infoHeadline">
									<h2>Leaderboard: MIMIC-III (Valid P_exe ≥ 99%)</h2>
								</div>
								<p>The final model output should contain the predicted SQL queries and "null" if abstained. We use R_exe for evaluating two settings: models that exceed precisions of 99% and 95%. We only rank models that meet the submission criteria (i.e., P_exe ≥ 99%) on the validation set and the rest are reported in the leaderboard but not ranked. We suggest first using the validation set to check whether your model can exceed P_exe = 99% or P_exe = 95% on the validation set. Here are P_exe and R_exe scores evaluated on the test set of EHRSQL MIMIC-III, where the model validation performance exceeds P_exe = 99%.</p>
								<table class="table performanceTable">
									<tr>
										<th>Rank</th>
										<th>Model</th>
										<th>P_exe</th>
										<th>R_exe</th>
									</tr>

									<tr>
										<td>
											<p>1</p>
											<span class="date label label-default">April 30, 2023</span>
										</td>
										<td style="word-break:break-word;">
											T5-base (Threshold-tuned)</a>
											<p class="institution">Baseline</p>
										</td>
										<td><b>100.0</b></td>
										<td><b>3.2</b></td>
									</tr>

									</tr>
								</table>
							</div>
						</div>
						<div class="infoCard">
							<div class="infoBody">
								<div class="infoHeadline">
									<h2>Leaderboard: MIMIC-III (Valid P_exe ≥ 95%)</h2>
								</div>
								<p>Here are the P_exe and R_exe scores evaluated on the test set of EHRSQL MIMIC-III, where the model validation performance exceeds P_exe = 95%.</p>
								<table class="table performanceTable">
									<tr>
										<th>Rank</th>
										<th>Model</th>
										<th>P_exe</th>
										<th>R_exe</th>
									</tr>

									<tr>
										<td>
											<p>1</p>
											<span class="date label label-default">April 30, 2023</span>
										</td>
										<td style="word-break:break-word;">
											T5-base (Threshold-tuned)</a>
											<p class="institution">Baseline</p>
										</td>
										<td><b>86.7</b></td>
										<td><b>91.7</b></td>
									</tr>

									</tr>
								</table>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
		<nav class="navbar navbar-default navbar-static-bottom footer">
			<div class="container clearfix">
				<div class="rightNav">
					<div>
						<ul class="nav navbar-nav navbar-right">
							<li><a href="/EHRSQL/">EHRSQL</a></li>
						</ul>
					</div>
				</div>
			</div>
		</nav>
		<script src="/EHRSQL/bower_components/jquery/dist/jquery.min.js"></script>
		<script src="/EHRSQL/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
	</body>
</html>
